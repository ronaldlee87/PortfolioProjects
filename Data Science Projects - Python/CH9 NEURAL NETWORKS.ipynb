{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CH9 NEURAL NETWORKS.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPRpfdD/sf23HOXHv1AG5+o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1e4ofHUoi8q2"},"source":["# CH 9 NEURAL NETWORKS"]},{"cell_type":"code","metadata":{"id":"splHcmgXH1Np"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","folder = \"/gdrive/My Drive/Python Practice/Datasets\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EI9X4y3KlJHi"},"source":["# HANDS-ON ANALYSIS\n"]},{"cell_type":"markdown","metadata":{"id":"FWUCqIIgNkt4"},"source":["---\n","# Use **adult_ch6_training**, **adult_ch6_test** Dataset below.\n","\n","---"]},{"cell_type":"code","metadata":{"id":"_7k77T9TlJHj"},"source":["import numpy as np\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import statsmodels.tools.tools as stattools\n","\n","#from tensorflow.keras.models import Sequential         # too much better performance\n","#from tensorflow.keras.layers import Dense              # too much better performance\n","#import tensorflow as tf\n","#np.random.seed(3)\n","#tf.random.set_seed(3)\n","\n","adult_train = pd.read_csv(folder + '/adult_ch6_training', delimiter=',')\n","adult_test = pd.read_csv(folder + '/adult_ch6_test', delimiter=',')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SXYly4dBlJHo"},"source":["#17\n","Prepare the data set for neural network modeling by doing the following:<br>\n","a.  Create a binary variable that equals one if Cap_Gains_Losses is greater than zero, and zero otherwise. Call it CapGainsLossesPositive.<br>\n","b.  Convert the Marital.status, Income, and CapGainsLossesPositive to factors."]},{"cell_type":"code","metadata":{"id":"78RSNQ9jITX_"},"source":["adult_train[\"CapGainsLossesPositive\"] = list(map(int, adult_train[\"Cap_Gains_Losses\"]>0))\n","adult_train.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqXd-_FGlJHp"},"source":["# change CapGainsLosses to binary\n","adult_train[\"CapGainsLossesPositive\"] = list(map(int, adult_train[\"Cap_Gains_Losses\"]>0))\n","\n","# change Income to numeric\n","adult_train[\"Income_factor\"] = list(map(int, adult_train[\"Income\"] == '>50K'))\n","\n","# convert 'Marital status' to factor\n","mar_np = np.array(adult_train['Marital status'])\n","(mar_cat, mar_cat_dict) = stattools.categorical(mar_np, drop=True, dictnames=True)\n","mar_cat_pd = pd.DataFrame(mar_cat)\n","\n","# create list of x names, y names\n","mar_names = list(set(adult_train['Marital status']))\n","X_names = ['Caps_Gains_Losses']\n","for i in mar_names:\n","    X_names.append(i)\n","y_names = [\"<=50K\", \">50K\"]\n","\n","# create x_train, y_train\n","X_train = pd.concat((adult_train['CapGainsLossesPositive'], mar_cat_pd), axis=1)\n","Y_train = adult_train['Income_factor']\n","# Y_train = pd.factorize(adult_train['Income'])[0]\n","X_train.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6I7mfY4kdOK"},"source":["# change CapGainsLosses to binary\n","adult_test[\"CapGainsLossesPositive\"] = list(map(int, adult_test[\"Cap_Gains_Losses\"]>0))\n","\n","# change Income to numeric\n","adult_test[\"Income_factor\"] = list(map(int, adult_test[\"Income\"] == '>50K'))\n","\n","# convert 'Marital status' to factor\n","mar_np = np.array(adult_test['Marital status'])\n","(mar_cat, mar_cat_dict) = stattools.categorical(mar_np, drop=True, dictnames=True)\n","mar_cat_pd = pd.DataFrame(mar_cat)\n","\n","# create list of x names, y names\n","mar_names = list(set(adult_test['Marital status']))\n","X_names = ['Caps_Gains_Losses']\n","for i in mar_names:\n","    X_names.append(i)\n","y_names = [\"<=50K\", \">50K\"]\n","\n","# create x_train, y_train\n","X_test = pd.concat((adult_test['CapGainsLossesPositive'], mar_cat_pd), axis=1)\n","Y_test = adult_test['Income_factor']\n","# Y_test = pd.factorize(adult_test['Income'])[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wx1Io8WalJHq"},"source":["#18\n","Using the training data set, create a neural network model to predict a customer’s Income using Marital.status and CapGainsLossesPositive. <br>\n","Call this NNM1 (For neural network Model 1). <br>\n","Obtain the predicted responses."]},{"cell_type":"code","metadata":{"id":"TcxXwVCMlJHr"},"source":["X_train = np.array(X_train)\n","Y_train = np.array(Y_train)\n","\n","NNM1 = Sequential()\n","NNM1.add(Dense(2, input_dim = 6, activation='relu'))\n","NNM1.add(Dense(1, activation='sigmoid'))\n","# compile the keras model \n","NNM1.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n","#NNM1.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n","NNM1.fit(X_train,Y_train, epochs=20, batch_size=5)\n","\n","scores = NNM1.evaluate(X_train, Y_train)\n","print('\\n%s: %.4f%%' % (NNM1.metrics_names[1], scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EiQ9no81lJHt"},"source":["print('\\n Accuracy: %.4f' % (NNM1.evaluate(X_train, Y_train)[1]))\n","print('\\n Test Accuracy: %.4f' % (NNM1.evaluate(X_test, Y_test)[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"slaP8uHYO_76"},"source":["#19\n","Plot the NNM1 neural network."]},{"cell_type":"code","metadata":{"id":"FJrGp3hxPk6E"},"source":["!pip install ann_visualizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oAwdRGnSPF3D"},"source":["from ann_visualizer.visualize import ann_viz\n","ann_viz(NNM1, title='NNM1', view=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y3hSrJlrSjKY"},"source":["#20\n","Evaluate NNM1 using the test data set. <br>\n","Construct a contingency table to compare the actual and predicted values of Income.\n"]},{"cell_type":"code","metadata":{"id":"jnP-MoONSxUR"},"source":["test_pred = NNM1.predict(X_test).flatten()\n","adult_pred = np.array([prob > 0.5 and 1 or 0 for prob in test_pred])\n","\n","crosstab_adult = pd.crosstab(Y_test, adult_pred, rownames=['Actual'], colnames=['Prediction'])\n","crosstab_adult"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rjWdIZ1LFMqK"},"source":["#21\n","Which baseline model do we compare NNM1 against? <br>\n","Did NNM1 outperform the base- line according to accuracy?"]},{"cell_type":"code","metadata":{"id":"Ux8UX2Y-Fi2F"},"source":["base_acc = crosstab_adult.sum(axis=1)[0] / sum(crosstab_adult.sum())\n","NN_acc = (crosstab_adult.iloc[0,0] + crosstab_adult.iloc[1,1]) / sum(crosstab_adult.sum())\n","print(\"Baseline model Accuracy: %.4f%%\" %base_acc)\n","print(\"Neural Network Accuracy: %.4f%%\" %NN_acc)\n","\n","# NN model outperform the baseline model "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nm7hTow-tulF"},"source":["############################################## 여기서 부터 다시 정리 #######################################################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZaBEmBj-TEQn"},"source":["#22\n","Gather the results (contingency tables) from your earlier modeling of the adult_ch6_ training and adult_ch6_test data sets in the Chapter 6 and Chapter 8 exercises. <br>\n","From Chapter  6, call the CART model CARTM1 and call the C5.0 model C5M1. <br>\n","From Chapter 8, call the Naïve Bayes model NBM1.\n"]},{"cell_type":"markdown","metadata":{"id":"m2iWUktuZqve"},"source":["* CART (CARTM1)"]},{"cell_type":"code","metadata":{"id":"IAyj4FbrBwKk"},"source":["from sklearn.tree import DecisionTreeClassifier, export_graphviz\n","from graphviz import Source\n","\n","#folder = \"/gdrive/My Drive/DSPR/DataSets\"\n","\n","adult_train = pd.read_csv(folder + \"/adult_ch6_training\", delimiter=',')\n","adult_test = pd.read_csv(folder + \"/adult_ch6_test\", delimiter=',')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_Dh2Cv9Htbg"},"source":["mar_np = np.array(adult_train['Marital status'])\n","(mar_cat, mar_cat_dict) = stattools.categorical(mar_np, drop=True, dictnames=True)\n","\n","mar_cat_pd = pd.DataFrame(mar_cat)\n","X_adult_tree = pd.concat((adult_train['Cap_Gains_Losses'], mar_cat_pd), axis=1)\n","\n","y_adult_tree = adult_train[['Income']]\n","\n","X_adult_names_tree = [\"Cap_Gains_Losses\", \"Divorced\", \"Married\",\"Never-married\",\"Separated\", \"Widowed\"]\n","y_adult_names_tree = [\"<=50K\", \">50K\"]\n","\n","CARTM1 = DecisionTreeClassifier(criterion = \"gini\", max_leaf_nodes = 5).fit(X_adult_tree, y_adult_tree)\n","export_graphviz(CARTM1, out_file = folder+\"/CARTM1.dot\", feature_names = X_adult_names_tree, class_names = adult_train['Income'].unique())\n","### CART model using Training set \n","Source.from_file(folder+\"/CARTM1.dot\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-T17YNrg2SR"},"source":["### Predict Test set\n","\n","mar_np_test = np.array(adult_test['Marital status'])\n","(mar_cat_test, mar_cat_dict_test) = stattools.categorical(mar_np_test, drop=True, dictnames=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kr_drwO2g2HM"},"source":["mar_cat_test_pd = pd.DataFrame(mar_cat_test)\n","X_adult_tree_test =  pd.concat((adult_test['Cap_Gains_Losses'], mar_cat_test_pd), axis=1)\n","\n","y_adult_tree_test = adult_test[['Income']]\n","\n","X_adult_names_tree = [\"Cap_Gains_Losses\", \"Divorced\", \"Married\",\"Never-married\",\"Separated\", \"Widowed\"]\n","y_adult_names_tree = [\"<=50K\", \">50K\"]\n","\n","adult_CART_pred = CARTM1.predict(X_adult_tree_test)\n","\n","adult_CART_crosstab = pd.crosstab(adult_test['Income'], adult_CART_pred)\n","adult_CART_crosstab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNL04Z3mg15z"},"source":["def eval(tab, level):\n","    GT = sum(tab.sum())\n","    TAP = tab.sum(1)[1]\n","    TAN = tab.sum(1)[0]\n","    TPP = tab.sum(0)[1]\n","    TP = tab[level[1]][1]\n","    TN = tab[level[0]][0]\n","\n","    acc = (TN + TP) / GT\n","    err = 1 - acc\n","    sen = TP / TAP\n","    spe = TN / TAN\n","    pre = TP / TPP\n","    \n","    return [round(acc, 4), round(err,4), round(sen,4), round(spe,4), round(pre,4)]\n","\n","def Fscore(pre, spe, df):\n","    val = ((1+df**2) * pre * spe) / ((df**2 * pre) + spe)\n","    return round(val, 4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"566QmGJ1ohp-"},"source":["acc_cart, err_cart, sen_cart, spe_cart, pre_cart = eval(adult_CART_crosstab, y_adult_names_tree)\n","acc_cart, err_cart, sen_cart, spe_cart, pre_cart"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7ZTqTCTv3O1"},"source":["Fscore(pre_cart, spe_cart, 1), Fscore(pre_cart, spe_cart, 2), Fscore(pre_cart, spe_cart, 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WANXbTAI-uBa"},"source":["measure_cart_01 = pd.DataFrame(eval(adult_CART_crosstab, y_adult_names_tree))\n","measure_cart_02 = Fscore(pre_cart, spe_cart, 1), Fscore(pre_cart, spe_cart, 2), Fscore(pre_cart, spe_cart, 0.5)\n","measure_cart_02 = pd.DataFrame(measure_cart_02)\n","measure_cart_02\n","\n","eval_cart = pd.concat((measure_cart_01, measure_cart_02), axis=0)\n","eval_cart.columns = ['CART']\n","eval_cart.index = ['Accuracy', 'Error rate', 'Sensitivity', 'Specificity', 'Precision', 'F1', 'F2', 'F0.5']\n","eval_cart"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zsjovUW2BwTd"},"source":["* C5.0 (C5M1)"]},{"cell_type":"code","metadata":{"id":"k7r7HnxTBweF"},"source":["C5M1 = DecisionTreeClassifier(criterion=\"entropy\",max_leaf_nodes=5).fit(X_adult_tree, y_adult_tree)\n","export_graphviz(C5M1, out_file = folder+\"/C5M1.dot\", feature_names = X_adult_names_tree, class_names = adult_train['Income'].unique())\n","### C5.0 model using Training set \n","Source.from_file(folder+\"/C5M1.dot\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nwxxj9R5RxH"},"source":["### Predict Test set\n","\n","adult_C5M1_pred = C5M1.predict(X_adult_tree_test)\n","\n","adult_C5M1_crosstab = pd.crosstab(adult_test['Income'], adult_C5M1_pred)\n","adult_C5M1_crosstab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTATIR7R5Rok"},"source":["acc_c5m1, err_c5m1, sen_c5m1, spe_c5m1, pre_c5m1 = eval(adult_C5M1_crosstab, y_adult_names_tree)\n","acc_c5m1, err_c5m1, sen_c5m1, spe_c5m1, pre_c5m1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vtPapP6H5Rgc"},"source":["Fscore(pre_c5m1, spe_c5m1, 1), Fscore(pre_c5m1, spe_c5m1, 2), Fscore(pre_c5m1, spe_c5m1, 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-hGWdMU8dUO"},"source":["measure_cm51_01 = pd.DataFrame(eval(adult_C5M1_crosstab, y_adult_names_tree))\n","measure_cm51_02 = Fscore(pre_c5m1, spe_c5m1, 1), Fscore(pre_c5m1, spe_c5m1, 2), Fscore(pre_c5m1, spe_c5m1, 0.5)\n","measure_cm51_02 = pd.DataFrame(measure_cm51_02)\n","measure_cm51_02\n","\n","eval_cm51 = pd.concat((measure_cm51_01, measure_cm51_02), axis=0)\n","eval_cm51.columns = ['C5.0']\n","eval_cm51.index = ['Accuracy', 'Error rate', 'Sensitivity', 'Specificity', 'Precision', 'F1', 'F2', 'F0.5']\n","eval_cm51"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I0PWnXSiBwod"},"source":["* Naive Bayes (NBM1)"]},{"cell_type":"code","metadata":{"id":"-FRNOpwkJfSS"},"source":["adult_train.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YuIAKjS5J4fu"},"source":["from sklearn.naive_bayes import MultinomialNB\n","import statsmodels.tools.tools as stattools\n","\n","def X_ind_ftn(data, col):\n","    X_ind = np.array(data[col])\n","    X_ind = pd.DataFrame(stattools.categorical(X_ind,drop=True, dictnames = False))\n","    return X_ind\n","\n","X_Mar_ind = X_ind_ftn(adult_train, \"Marital status\")\n","    \n","X_naive = pd.concat((X_Mar_ind, adult_train['Cap_Gains_Losses']), axis=1)\n","y_naive = adult_train[\"Income\"]\n","\n","nb_adult = MultinomialNB().fit(X_naive,y_naive)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXWTJwlGBw0F"},"source":["# Test NB algorithm by Test set\n","X_Mar_ind_test = X_ind_ftn(adult_test, 'Marital status')\n","\n","X_naive_test = pd.concat((X_Mar_ind_test, adult_test['Cap_Gains_Losses']), axis=1)\n","y_naive_test = adult_test['Income']\n","\n","adult_naive_pred = nb_adult.predict(X_naive_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PzbRZ--x0Nm6"},"source":["adult_naive_crosstab = pd.crosstab(y_naive_test, adult_naive_pred, rownames=['Actual'], colnames=['Predicted'])\n","adult_naive_crosstab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iAW7tu3uBxLt"},"source":["acc_naive, err_naive, sen_naive, spe_naive, pre_naive = eval(adult_naive_crosstab, y_adult_names_tree)\n","acc_naive, err_naive, sen_naive, spe_naive, pre_naive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZeugjas0wy_"},"source":["Fscore(pre_naive, spe_naive, 1), Fscore(pre_naive, spe_naive, 2), Fscore(pre_naive, spe_naive, 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R8yNpvVu0w60"},"source":["measure_naive_01 = pd.DataFrame(eval(adult_naive_crosstab, y_adult_names_tree))\n","measure_naive_02 = Fscore(pre_naive, spe_naive, 1), Fscore(pre_naive, spe_naive, 2), Fscore(pre_naive, spe_naive, 0.5)\n","measure_naive_02 = pd.DataFrame(measure_naive_02)\n","measure_naive_02\n","\n","eval_naive = pd.concat((measure_naive_01, measure_naive_02), axis=0)\n","eval_naive.columns = ['Naive Bayes']\n","eval_naive.index = ['Accuracy', 'Error rate', 'Sensitivity', 'Specificity', 'Precision', 'F1', 'F2', 'F0.5']\n","eval_naive"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QTw6GeB_Zr_D"},"source":["#23\n","Compare the NNM1 results with the three models from the previous exercise, according to the following criteria.<br>\n","Discuss in detail which model performed best and worst according to each criterion.<br>\n","a.  Accuracy<br>\n","b.  Sensitivity<br>\n","c.  Specificity"]},{"cell_type":"code","metadata":{"id":"0ug56UFf2R4v"},"source":["pd.concat((eval_cart, eval_cm51, eval_naive), axis=1)\n","# should have added Neural Network model...."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1cuJk5g9N9Qo"},"source":["---\n","# Use **bank_marketing_training**, **bank_marketing_test** Dataset below.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"TkA7LCm9aF5E"},"source":["#24\n","Prepare the data set for neural network modeling, including standardizing the variables.\n"]},{"cell_type":"code","metadata":{"id":"T8hSxoPmbsHz"},"source":["bank_train = pd.read_csv(folder + \"/bank_marketing_training\", delimiter=',')\n","bank_test = pd.read_csv(folder + \"/bank_marketing_test\", delimiter=',')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3AQdJhFlbsH0"},"source":["import statsmodels.tools.tools as stattools\n","\n","# change 'Response' to numeric(binary)\n","bank_train[\"response_factor\"] = list(map(int, bank_train[\"response\"] == 'yes'))\n","\n","# convert 'job', 'marital', 'education' to factor\n","# job\n","job_np = np.array(bank_train['job'])\n","(job_cat, job_cat_dict) = stattools.categorical(job_np, drop=True, dictnames=True)\n","# marital\n","mari_np = np.array(bank_train['marital'])\n","(mari_cat, mari_cat_dict) = stattools.categorical(mari_np, drop=True, dictnames=True)\n","# education\n","edu_np = np.array(bank_train['education'])\n","(edu_cat, edu_cat_dict) = stattools.categorical(edu_np, drop=True, dictnames=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xFutnf2i2z_J"},"source":["bank_train['job'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B5WgxziYbsH1"},"source":["job_cat_pd = pd.DataFrame(job_cat)\n","mari_cat_pd = pd.DataFrame(mari_cat)\n","edu_cat_pd = pd.DataFrame(edu_cat)\n","\n","X_bank = pd.concat((bank_train['age'], job_cat_pd, mari_cat_pd, edu_cat_pd), axis=1)\n","\n","#X_bank_names = [ ... ]\n","#Y_bank_names = ['yes', 'no']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Opnc5__-bsH2"},"source":["X_bank.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UcaA8f03bsH2"},"source":["#X_bank.head()\n","y_bank = bank_train['response_factor']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MJoabKGbsH3"},"source":["model2 = Sequential()\n","model2.add(Dense(30, input_dim = 25, activation='relu'))\n","model2.add(Dense(1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"za4oUSDgbsH4"},"source":["model2.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKMlEgpFbsH4"},"source":["model2.fit(X_bank, y_bank, epochs=5, batch_size=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHerhWA7bsH4"},"source":["print('\\n Accuracy: %.4f' % (model2.evaluate(X_bank, y_bank)[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jc8ZeK1IbsH5"},"source":["bank_test[\"response_factor\"] = list(map(int, bank_test[\"response\"] == 'yes'))\n","\n","job_np_test = np.array(bank_test['job'])\n","(job_cat_test, job_cat_dict_test) = stattools.categorical(job_np_test, drop=True, dictnames=True)\n","\n","mari_np_test = np.array(bank_test['marital'])\n","(mari_cat_test, mari_cat_dict_test) = stattools.categorical(mari_np_test, drop=True, dictnames=True)\n","\n","edu_np_test = np.array(bank_test['education'])\n","(edu_cat_test, edu_cat_dict_test) = stattools.categorical(edu_np_test, drop=True, dictnames=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bn5lCPZWbsH5"},"source":["job_cat_test_pd = pd.DataFrame(job_cat_test)\n","mari_cat_test_pd = pd.DataFrame(mari_cat_test)\n","edu_cat_test_pd = pd.DataFrame(edu_cat_test)\n","\n","X_bank_test = pd.concat((bank_test['age'], job_cat_test_pd, mari_cat_test_pd, edu_cat_test_pd), axis=1)\n","\n","#X_bank_names = [ ... ]\n","#Y_bank_names = ['yes', 'no']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9M3cKuzubsH5"},"source":["#X_bank_test.head()\n","y_bank_test = bank_test['response_factor']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xr1ua34ebsH6"},"source":["print('\\n Test Accuracy: %.4f' % (model2.evaluate(X_bank_test, y_bank_test)[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k3YcTb3AbsH6"},"source":["y_bank_prediction = model2.predict(X_bank_test).flatten()\n","bank_pred = pd.concat((pd.DataFrame(y_bank_prediction), y_bank_test), axis=1) \n","\n","bank_tab = pd.crosstab(y_bank_test, y_bank_prediction, rownames=['Actual'], colnames=['Prediction'])\n","bank_tab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LdEVHnyB9Rzf"},"source":["# ????????????????????????? all 1 on prediction? "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fXAD81akaSyd"},"source":["#25\n","Using the training data set, create a neural network model to predict a customer’s Response using whichever predictors you think appropriate. <br>\n","Obtain the predicted responses.\n"]},{"cell_type":"code","metadata":{"id":"GKWH9yOjaeh0"},"source":["y_bank_prediction # all 0 ????"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UKVkyPqQafKj"},"source":["#26\n","Plot the neural network."]},{"cell_type":"code","metadata":{"id":"LG3rSZomafWF"},"source":["# ????????????"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9zSa7N9xafei"},"source":["#27\n","Evaluate the neural network model using the test data set. <br>\n","Construct a contingency table to compare the actual and predicted values of Response.\n"]},{"cell_type":"code","metadata":{"id":"cMt6JEPQafms"},"source":["bank_tab"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S6EW7nSKazEK"},"source":["#28\n","Which baseline model do we compare your neural network model against? <br>\n","Did it out- perform the baseline according to accuracy?\n"]},{"cell_type":"code","metadata":{"id":"UOjCyRp-a_EU"},"source":["# ???"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qHObpxMZa_PQ"},"source":["#29\n","Using the same predictors you used for your neural network model, build models to pre- dict Response using the following algorithms:<br>\n","a. CART<br>\n","b.  C5.0<br>\n","c.  Naïve Bayes"]},{"cell_type":"code","metadata":{"id":"LfIMENlwa_Xt"},"source":["bank_train.head() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQjqu8T4OpUq"},"source":["bank_train['education'].unique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cd5-YmZDAsz1"},"source":["def X_ind_ftn(data, col):\n","    X_ind = np.array(data[col])\n","    X_ind = pd.DataFrame(stattools.categorical(X_ind,drop=True, dictnames = False))\n","    return X_ind\n","\n","X_job_ind = X_ind_ftn(bank_train, \"job\")\n","X_marital_ind = X_ind_ftn(bank_train, \"marital\")\n","X_edu_ind = X_ind_ftn(bank_train, \"education\")\n","\n","X_bank_tree = pd.concat((bank_train[['age']],X_job_ind, X_marital_ind, X_edu_ind), axis=1)\n","X_bank_tree\n","\n","y_bank_tree = bank_train[['response']]\n","\n","X_bank_names_tree = [\"age\", \"housemaid\", \"services\",\"blue-collar\",\"management\", \"unemployed\", \"retired\", \"technician\", \"admin.\",\"unknown\",\"entrepreneur\",\"student\",\"self-employed\",\n","                     \"married\",\"single\",\"divorced\",\"unknown\",\n","                     \"basic.4y\",\"high.school\",\"unknown\",\"basic.6y\",\"basic.9y\",\"university.degree\",\"prefessional.course\",\"illiterate\"]\n","y_bank_names_tree = [\"yes\", \"no\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FFhqVjAPXPV"},"source":["CART_bank = DecisionTreeClassifier(criterion = \"gini\", max_leaf_nodes = 5).fit(X_bank_tree, y_bank_tree)\n","export_graphviz(CART_bank, out_file = folder+\"/CART_bank.dot\", feature_names = X_bank_names_tree, class_names = bank_train['response'].unique())\n","### CART model using Training set \n","Source.from_file(folder+\"/CART_bank.dot\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmEyX7KRT2iX"},"source":["X_job_ind_test = X_ind_ftn(bank_test, \"job\")\n","X_marital_ind_test = X_ind_ftn(bank_test, \"marital\")\n","X_edu_ind_test = X_ind_ftn(bank_test, \"education\")\n","\n","X_bank_tree_test =  pd.concat((bank_test['age'], X_job_ind_test, X_marital_ind_test, X_edu_ind_test), axis=1)\n","\n","y_bank_tree_test = bank_test[['response']]\n","\n","bank_CART_pred = CART_bank.predict(X_bank_tree_test)\n","\n","bank_CART_crosstab = pd.crosstab(bank_test['response'], bank_CART_pred, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n","bank_CART_crosstab  # no yes??"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7bLSf253Pcpn"},"source":["acc_bank_cart, err_bank_cart, sen_bank_cart, spe_bank_cart, pre_bank_cart = eval(bank_CART_crosstab, y_bank_names_tree)\n","acc_bank_cart, err_bank_cart, sen_bank_cart, spe_bank_cart, pre_bank_cart\n","\n","Fscore(pre_bank_cart, spe_bank_cart, 1), Fscore(pre_bank_cart, spe_bank_cart, 2), Fscore(pre_bank_cart, spe_bank_cart, 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dPGOlbvsPhQu"},"source":["bank_cart_01 = pd.DataFrame(eval(bank_CART_crosstab, y_bank_names_tree))\n","bank_cart_02 = Fscore(pre_bank_cart, spe_bank_cart, 1), Fscore(pre_bank_cart, spe_bank_cart, 2), Fscore(pre_bank_cart, spe_bank_cart, 0.5)\n","bank_cart_02 = pd.DataFrame(bank_cart_02)\n","bank_cart_02"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVlu4DIBPijn"},"source":["eval_bank_cart = pd.concat((bank_cart_01, bank_cart_02), axis=0)\n","eval_bank_cart.columns = ['CART']\n","eval_bank_cart.index = ['Accuracy', 'Error rate', 'Sensitivity', 'Specificity', 'Precision', 'F1', 'F2', 'F0.5']\n","eval_bank_cart"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HBXpletNbNOb"},"source":["* C5.0"]},{"cell_type":"code","metadata":{"id":"uNjM4DtvYlGa"},"source":["C5M1_bank = DecisionTreeClassifier(criterion=\"entropy\",max_leaf_nodes=5).fit(X_bank_tree, y_bank_tree)\n","export_graphviz(C5M1_bank, out_file = folder+\"/C5M1_bank.dot\", feature_names = X_bank_names_tree, class_names = bank_train['response'].unique())\n","### C5.0 model using Training set \n","Source.from_file(folder+\"/C5M1_bank.dot\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fKuP5METYlGl"},"source":["### Predict Test set\n","\n","bank_C5M1_pred = C5M1_bank.predict(X_bank_tree_test)\n","\n","bank_C5M1_crosstab = pd.crosstab(bank_test['response'], bank_C5M1_pred)\n","bank_C5M1_crosstab # no yes??"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"88TTLq8AYlGl"},"source":["acc_bank_c5m1, err_bank_c5m1, sen_bank_c5m1, spe_bank_c5m1, pre_bank_c5m1 = eval(bank_C5M1_crosstab, y_bank_names_tree)\n","acc_bank_c5m1, err_bank_c5m1, sen_bank_c5m1, spe_bank_c5m1, pre_bank_c5m1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tyLS_1qBYlGl"},"source":["Fscore(pre_bank_c5m1, spe_bank_c5m1, 1), Fscore(pre_bank_c5m1, spe_bank_c5m1, 2), Fscore(pre_bank_c5m1, spe_bank_c5m1, 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_23EKVVYlGl"},"source":["bank_cm51_01 = pd.DataFrame(eval(bank_C5M1_crosstab, y_bank_names_tree))\n","bank_cm51_02 = Fscore(pre_bank_c5m1, spe_bank_c5m1, 1), Fscore(pre_bank_c5m1, spe_bank_c5m1, 2), Fscore(pre_bank_c5m1, spe_bank_c5m1, 0.5)\n","bank_cm51_02 = pd.DataFrame(bank_cm51_02)\n","bank_cm51_02\n","\n","eval_bank_cm51 = pd.concat((bank_cm51_01, bank_cm51_02), axis=0)\n","eval_bank_cm51.columns = ['C5.0']\n","eval_bank_cm51.index = ['Accuracy', 'Error rate', 'Sensitivity', 'Specificity', 'Precision', 'F1', 'F2', 'F0.5']\n","eval_bank_cm51"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VBhgiKEcbNgt"},"source":["* Naive Bayes"]},{"cell_type":"code","metadata":{"id":"FQIU9YWdbQR1"},"source":["####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EvtM1geqbQbm"},"source":["#30\n","Compare the results of your neural network model with the three models from the previous exercise, according to the following criteria. <br>\n","Discuss in detail which model performed best and worst according to each criterion.<br>\n","a. Accuracy<br>\n","b.  Sensitivity<br>\n","c.  Specificity"]},{"cell_type":"code","metadata":{"id":"_ej6j6y1bWg5"},"source":["####"],"execution_count":null,"outputs":[]}]}